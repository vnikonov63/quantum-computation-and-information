\documentclass{article}
\usepackage{amsmath, amssymb, framed}  
\usepackage{amsthm}            
\usepackage{booktabs} 
\usepackage{float} 
\usepackage{graphicx}          
\usepackage{hyperref}          
\usepackage{enumitem}     
\usepackage{braket}
\usepackage{wasysym}
\usepackage{graphicx} 
\usepackage{caption}
\usepackage[margin=1in]{geometry}  
\usepackage[table]{xcolor}
\usepackage{booktabs}
\usepackage{placeins}
\usepackage[american]{circuitikz}

\ctikzset{logic ports=american}

\newcommand{\solved}[1]{\colorbox{green!30}{\textbf{#1}}}
\newcommand{\inProgress}[1]{\colorbox{yellow!30}{\textbf{#1}}}
\newcommand{\notStarted}[1]{\colorbox{red!30}{\textbf{#1}}}

\title{Quantum Computation and Quantum Information by Michael A. Nielsen and Isaac L. Chuang}
\author{Vasilii Nikonov}
\date{San Diego, CA February 2025}

\begin{document}

\maketitle

\subsection*{Chapter 2: Introduction to quantum mechanics}

\begin{center}
\begin{tabular}{*{5}{c}}
\toprule
\solved{1} & \solved{2} & \solved{3} & \notStarted{4} & \notStarted{5} \\
\solved{6} & \solved{7} & \notStarted{8} & \solved{9} & \notStarted{10} \\
\inProgress{11} & \inProgress{12} & \solved{13} & \solved{14} & \solved{15} \\
\solved{16} & \solved{17} & \solved{18} & \solved{19} & \notStarted{20} \\
\notStarted{21} & \notStarted{22} & \notStarted{23} & \inProgress {24} & \solved{25} \\
\solved{26} & \solved{27} & \notStarted{28} & \solved{29} & \solved{30} \\
\inProgress{31} & \notStarted{32} & \inProgress{33} & \notStarted{34} & \notStarted{35} \\
\solved{36} & \inProgress{37} & \solved{38} & \notStarted{39} & \solved{40} \\
\solved{41} & \solved{42} & \solved{43} & \solved{44} & \solved{45} \\
\solved{46} & \solved{47} & \notStarted{48} & \notStarted{49} & \notStarted{50} \\
\solved{51} & \solved{52} & \inProgress{53} & \notStarted{54} & \notStarted{55} \\
\notStarted{56} & \notStarted{57} & \notStarted{58} & \notStarted{59} & \notStarted{60} \\
\notStarted{61} & \notStarted{62} & \notStarted{63} & \notStarted{64} & \notStarted{65} \\
\notStarted{66} & \notStarted{67} & \notStarted{68} & \notStarted{69} & \notStarted{70} \\
\notStarted{71} & \notStarted{72} & \notStarted{73} & \notStarted{74} & \notStarted{75} \\
\notStarted{76} & \notStarted{77} & \notStarted{78} & \notStarted{79} & \notStarted{80} \\
\notStarted{81} & \notStarted{82} & \notStarted{EOC1} & \notStarted{EOC2} & \notStarted{EOC3} \\
\bottomrule
\end{tabular}
\end{center}

\begin{framed}
    \noindent \textbf{Exercise 2.1: (Linear Dependence Example)}
    
    \medskip
    We can observe that:
    $$
    (1, -1) + (1, 2) - (2, 1) = (0,0) = \boldsymbol{0}
    $$
    Thus, the set of three provided vectors is linearly dependent.
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.2: (Matrix Representations: Example)}

    \medskip
    $V$ is a vector space with basis $\{ \ket{0}, \ket{1} \}$. \\
    $$
        A\ket{0} = \ket{1} \implies A\begin{bmatrix} 1 \\ 0 \end{bmatrix} = \begin{bmatrix} 0 \\ 1 \end{bmatrix} \implies \text{ first column of A is } 
        \ket{1}
    $$
    as multiplication of a 2 by 2 matrix by  $\ket{0}$ is just extracting the first column. Also
    $$
        A\ket{1} = \ket{0} \implies A\begin{bmatrix} 0 \\ 1 \end{bmatrix} = \begin{bmatrix} 1 \\ 0 \end{bmatrix} \implies \text{ second column of A is } \ket{0}
    $$
    Thus $A = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}$. \\ \\ 
    We know, from (2.7), that $\ket{v_1} = \ket{+} = \begin{bmatrix} \frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} \end{bmatrix}$ and $\ket{v_2} = \ket{-} = \begin{bmatrix} \frac{1}{\sqrt{2}} \\ \frac{-1}{\sqrt{2}} \end{bmatrix}$ span the $\mathbb{C}^{2}$, they also form a basis for $\mathbb{C}^2$, as they are linearly independent (the only solution for $c_1\ket{+} + c_2\ket{-} = 0$ is trivial). \\ \\ 
    So we can form following linear operators $A_i$ from $\mathbb{C}^{2}$ to $\mathbb{C}^{2}$ :
    \begin{enumerate}
        \item $A_1\ket{0} = \ket{+}$ and $A_1\ket{1} = \ket{-}$
        \item $A_2\ket{0} = \ket{-}$ and $A_2\ket{1} = \ket{+}$
        \item $A_3\ket{+} = \ket{0}$ and $A_3\ket{-} = \ket{1}$
        \item $A_4\ket{+} = \ket{1}$ and $A_4\ket{-} = \ket{0}$
    \end{enumerate}
    We can compute $A_2 = \begin{bmatrix} a & b \\ c & d \end{bmatrix}$, where $ \begin{bmatrix} a & b \\ c & d \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} = \begin{bmatrix} \frac{1}{\sqrt{2}} \\ \frac{-1}{\sqrt{2}} \end{bmatrix}$ and $ \begin{bmatrix} a & b \\ c & d \end{bmatrix} \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \begin{bmatrix} \frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} \end{bmatrix}$. We can trivially see, that $A_2 = \begin{bmatrix} \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \\ \frac{-1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \end{bmatrix}$ \\ \\ 
    A case $A_3 = \begin{bmatrix} e & f \\ g & h \end{bmatrix}$ is a bit more interesting, because we cannot just extract the columns. We can write in matrix form.
    $$
    \begin{bmatrix} e & f \\ g & h \end{bmatrix} \begin{bmatrix} \frac{1}{\sqrt{2}} && \frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} && \frac{-1}{\sqrt{2}} \end{bmatrix} = I
    $$
    We can multiply both sides on the right by a transpose of the second matrix, as it is orthogonal.
    $$
    A_3 = \begin{bmatrix} e & f \\ g & h \end{bmatrix} = \begin{bmatrix} \frac{1}{\sqrt{2}} && \frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} && \frac{-1}{\sqrt{2}} \end{bmatrix}
    $$
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.3: (Matrix representation for operator products)}

    \medskip
    We have the following combination of linear operators and vector spaces $V \xrightarrow{A} W \xrightarrow{B} X$. From (2.12) we can write: 
    \begin{equation}
        A\ket{v_i} = \sum_{j}{A_{ji}\ket{w_j}}\text{, and } B\ket{w_j} = \sum_{k}{B_{kj}\ket{x_k}} 
        \tag{1}
    \end{equation}
    $$BA\ket{v_j} = B(\sum_{j}{A_{ji}\ket{v_j}}) \text{ from (1)}$$
    $$
    B(\sum_{j}{A_{ji}\ket{v_j}}) = \sum_{j}{A_{ji}B(\ket{v_j}}) \text{ from linearity of inputs in (2.10)}
    $$
    $$
     = \sum_{j}{A_{ji}\sum_{k}{B_{kj}\ket{x_k}}} \text{ from (1)}
    $$
    \begin{equation}
    = \sum_k(\sum_j{B_{kj}A_{ji}) \ket{x_k}} \text{ rearranging the sum order}
    \tag{2}
    \end{equation}
    If we look from the point of view of a linear operation from V to X, then we need to have some matrix $C$, that would give us:
    $$C\ket{v_i} = \sum_k{C_{ki}\ket{x_k}}$$
    It is precisely 
    $$
    BA_{ki} = \sum_j{B_{kj}A_{ji}} \text{ from (2)}
    $$
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.4: (Matrix representation for identity)}

    \medskip
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.5}

    \medskip
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.6}
    
    \medskip
    
    Here we need to show, that any inner product $(\cdot, \cdot)$ is conjugate-linear in the first argument.
    $$
    (\sum_{i}{\lambda_i \ket{w_i}}, \ket{v}) = (\ket{v}, \sum_{i}{\lambda_i \ket{w_i}})^{*} \text{ from (2.13 (2))}
    $$
    $$
    = (\sum_{i}{\lambda_i(\ket{v}, \ket{w_i})})^{*} \text{ from linearity of second inner-product argument (2.13 (1))}
    $$
    $$
    = \sum_{i}{(\lambda_i(\ket{v}, \ket{w_i}))^*} \text{ as conjugate of a sum is a sum of conjugates}
    $$
    $$
    = \sum_{i}{\lambda_i^*(\ket{v}, \ket{w_i})^*}  \text{ as conjugate of a product is a product of conjugates}
    $$
    $$
    = \sum_{i}{\lambda_i^*(\ket{w_i}, \ket{v})} \text{ from (2.13 (2))}
    $$
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.7}
    
    \medskip
    
    $(\ket{v}, \ket{w}) =  ((1, -1), (1, 1)) = \begin{bmatrix} 1^* -1^* \end{bmatrix} \begin{bmatrix} 1^* \\ 1^* \end{bmatrix} = \begin{bmatrix} 1 -1 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \end{bmatrix} = 1 - 1 = 0$. Precisely following (2.14) we establish, that $\ket{w} \text{ and } \ket{v} \text{ are orthogonal}$. Their normalized forms are $\frac{v}{\| \ket{v \|}} = (\frac{1}{\sqrt{2}}, \frac{-1}{\sqrt{2}})$ and $\frac{w}{\| \ket{w \|}} = (\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}})$, as both have a norm of $\sqrt{2}$.
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.8}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.9: (Pauli operators and the outer product)}
    
    \medskip

    Consider:
    \begin{itemize}
        \item $\ket{0}\bra{0} = \begin{bmatrix}1 \\ 0\end{bmatrix}\begin{bmatrix}1 & 0\end{bmatrix} = \begin{bmatrix}1 & 0\\ 0 & 0\end{bmatrix}$
        \item $\ket{0}\bra{1} = \begin{bmatrix}1 \\ 0\end{bmatrix}\begin{bmatrix}0 & 1\end{bmatrix} = \begin{bmatrix}0 & 1\\ 0 & 0\end{bmatrix}$
        \item $\ket{1}\bra{0} = \begin{bmatrix}0 \\ 1\end{bmatrix}\begin{bmatrix}1 & 0\end{bmatrix} = \begin{bmatrix}0 & 0\\ 1 & 0\end{bmatrix}$
        \item $\ket{1}\bra{1} = \begin{bmatrix}0 \\ 1\end{bmatrix}\begin{bmatrix}0 & 1\end{bmatrix} = \begin{bmatrix}0 & 0\\ 0 & 1\end{bmatrix}$
    \end{itemize}
    \text{As if we are just setting a specific bit of the matrix (each outer product only has 1 non-zero value).}
    \begin{itemize}
        \item $X = \begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} = \ket{0}\bra{1} + \ket{1}\bra{0}$
        \item $Y=\begin{bmatrix}0 & -i \\ i & 0\end{bmatrix} = i\ket{0}\bra{1} - i\ket{1}\bra{0}$ 
        \item $Z=\begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix} = \ket{0}\bra{0} - \ket{1}\bra{1}$
    \end{itemize}
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.10}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.11: (Eigendecomposition of the Pauli matrices)}
    
    \medskip
    \begin{enumerate}
        \item X = $\begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} \implies $characteristic equation is $det(\begin{bmatrix} - \lambda & 1 \\ 1 & -\lambda \end{bmatrix}) = \lambda^2 - 1$ and the solution is $\lambda = \pm1$.
        \begin{enumerate}
            \item $\lambda = 1$, Solving $X\ket{v} = \ket{v} \implies \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}\begin{bmatrix} v_1 \\ v_2 \end{bmatrix}=\begin{bmatrix} v_1 \\ v_2 \end{bmatrix} \implies \begin{bmatrix} v_2 \\ v_1 \end{bmatrix}=\begin{bmatrix} v_1 \\ v_2 \end{bmatrix}$. Thus the eigenvector is any scalar multiple of $\begin{bmatrix} 1 \\ 1 \end{bmatrix}$\\
            \item $\lambda = -1$, Solving $X\ket{v} = -\ket{v} \implies \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}\begin{bmatrix} v_1 \\ v_2 \end{bmatrix}=\begin{bmatrix} -v_1 \\ -v_2 \end{bmatrix} \implies \begin{bmatrix} v_2 \\ v_1 \end{bmatrix} = \begin{bmatrix} -v_1 \\ -v_2 \end{bmatrix}$. Thus the eigenvector is any scalar multiple of $\begin{bmatrix} 1 \\ -1 \end{bmatrix}$
        \end{enumerate}
        \item Y = $\begin{bmatrix} 0 & -i \\ i & 0 \end{bmatrix} \implies $characteristic equation is $det(\begin{bmatrix} - \lambda & -i \\ i & -\lambda \end{bmatrix}) = \lambda^2 - 1$ and the solution is $\lambda = \pm 1$
        \begin{enumerate}
            \item $\lambda = 1$, Solving $Y\ket{v} = i\ket{v} \implies \begin{bmatrix}0 & -i \\ i & 0\end{bmatrix}\begin{bmatrix}v_1 \\ v_2\end{bmatrix} = \begin{bmatrix}v_1 \\ v_2\end{bmatrix} \implies \begin{bmatrix}-iv_2 \\ iv_1\end{bmatrix} = \begin{bmatrix}v_1 \\ v_2\end{bmatrix}$
            \item $\lambda = -1$, Solving $Y\ket{v} = -i\ket{v} \implies \begin{bmatrix}0 & -i \\ i & 0\end{bmatrix}\begin{bmatrix}v_1 \\ v_2\end{bmatrix} = \begin{bmatrix}-v_1 \\ -v_2\end{bmatrix} \implies  \begin{bmatrix}-iv_2 \\ iv_1\end{bmatrix}= \begin{bmatrix}-v_1 \\ -v_2\end{bmatrix}$
        \end{enumerate}
        \item Z = $\begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix} \implies$ characteristic equation is $\det(\begin{bmatrix} 1 - \lambda & 0 \\ 0 & -1 - \lambda \end{bmatrix}) = \lambda^2 - 1$, and the solution is $\lambda = \pm1$.
        \begin{enumerate}
            \item $\lambda = 1$, Solving $Z\ket{v} = \ket{v} \implies \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix} \begin{bmatrix} v_1 \\ v_2 \end{bmatrix} = \begin{bmatrix} v_1 \\ v_2 \end{bmatrix} \implies \begin{bmatrix} v_1 \\ -v_2 \end{bmatrix} = \begin{bmatrix} v_1 \\ v_2 \end{bmatrix}.$ Thus the eigenvector is any scalar multiple of $\begin{bmatrix} 1 \\ 0 \end{bmatrix}$

            \item $\lambda = -1$, Solving $Z\ket{v} = -\ket{v} \implies \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix} \begin{bmatrix} v_1 \\ v_2 \end{bmatrix} = \begin{bmatrix} -v_1 \\ -v_2 \end{bmatrix} \implies \begin{bmatrix} v_1 \\ -v_2 \end{bmatrix} = \begin{bmatrix} -v_1 \\ -v_2 \end{bmatrix}.$ Thus the eigenvector is any scalar multiple of $\begin{bmatrix} 0 \\ 1 \end{bmatrix}$
        \end{enumerate}
    \end{enumerate}

\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.12}
    
    \medskip

    $$
    \text{Consider } A - \lambda I = \begin{bmatrix}1 - \lambda & 0 \\ 1& 1 - \lambda\end{bmatrix} \implies \det(A -\lambda I) = (1 - \lambda)^{2} = 0 \implies \lambda = 1 \text{ is the only eigenvalue.}
    $$
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.13}
    
    \medskip

    $$
    (\ket{w}\bra{v})^{\dagger} = \bra{v}^{\dagger}\ket{w}^{\dagger} \text{ from the fact, that } (AB)^{\dagger} = B^{\dagger}A^{\dagger}. 
    $$
    $$
        \bra{v}^{\dagger}\ket{w}^{\dagger} = \ket{v}\bra{w} \text{ by convention}
    $$
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.14: (Anti-linearity of the adjoint)}
    
    \medskip

    $$
    \text{Consider } (\sum_i{a_iA_i})^{*} = \sum_i{(a_iA_i)^{*}} = \sum_i{a_i^*A_i^*} \text{ as conjugation is linear}
    $$

    $$
    \text{ Now consider } ((\sum_i{a_iA_i})^{*})^{T} = (\sum_i{a_i^*A_i^*})^{T} = \sum_i{a_i^*(A_i^*)^{T}} = \sum_i{a_i^*A_i^{\dagger}}\text{ as } a_i \text{ is a scalar }
    $$

    $$
    \text{ Thus we have established, that adjoint operation is anti-linear, namely: } \sum_i{a_iA_i}^{\dagger} = \sum_i{a_i^{*}A_i^{\dagger}}
    $$
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.15}
    
    \medskip
    
    $(A^{\dagger})^{\dagger} = ((A^{\dagger})^{T})^{*} = (((A^{T})^{*})^{T})^{*} = (((A^{T})^{*})^{*})^{T}$, as taking a conjugate and transposing can easily be interchanged. Conjugating each element in the matrix twice just yields the same initial value, as $(z^{*})^{*} = z , \forall z \in \mathbb{C}$ So we have: $((A^T)^T) = A$ from the definition of the transpose. 
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.16}
    
    \medskip
    $$
    \text{We can write out } P^2 \text{ explicitly using (2.35) } P^{2} = (\sum_{i=1}^{k}{\ket{i}\bra{i}})(\sum_{j=1}^{k}{\ket{j}\bra{j}}) = \sum_{i=1}^{k}\sum_{j=1}^{k}\ket{i}\bra{i}\ket{j}\bra{j}
    $$
    $$
    \text{As we have orthonormality} \bra{i}\ket{j} = \delta_{ij} = \begin{cases}1 & i=j \\ 0 & i \neq j\end{cases} \text{ the above double sum colapses into}
    $$
    $$
    \text{a single sum }\sum_{i=1}^{k}{\ket{i}\bra{i}} = P
    $$
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.17}
    
    \medskip

    \textbf{!TODO: ASK A QUESTION DID I SPLIT THE IFF CORRECTLY HERE!}
    $$
    \implies \text{Hermitian matrix has real eigenvalues.}
    $$
    \begin{equation}
        \text{Consider } (\ket{v}, H\ket{v}) = (H^{\dagger}\ket{v}, \ket{v}) = (H\ket{v}, \ket{v})
    \end{equation}
    $$
    (\ket{v},H\ket{v}) = (\ket{v},\lambda\ket{v}) = \lambda(\ket{v},\ket{v}) \text{ from (2.13)}
    $$
    $$
    \text{From (1) } (\ket{v}, H\ket{v}) = (\lambda\ket{v}, \ket{v}) = \lambda^{*}(\ket{v}, \ket{v}) \text{ from (2.15)}.
    $$
    $$
    \text{We have } \lambda(\ket{v},\ket{v}) = (\ket{v}, H\ket{v}) = \lambda^{*} (\ket{v},\ket{v}) \implies \lambda^{*} = \lambda \implies \text{ eigenvalue is real}
    $$
    $$
    \text{As complex conjugate of a complex number is equal to itself and thus imaginary part is zero}.
    $$
    $$
    \impliedby \text{A normal matrix that has real eigenvalues is Hermitian}
    $$
    $$
    \text{From Theorem 2.1 on page 71 we know, that any normal operator on a vector space V is diagonal} 
    $$
    $$
    \text{with respect to some orthonormal basis for V. Thus it has a diagonal representation. Namely:}
    $$
    $$
    A = \sum_{i}{\lambda_i}\ket{i}\bra{i} \text{, where the vectors} \ket{i} \text{form an orthonormal set of eigenvectors for A}.
    $$
    $$
    \text{with corresponding eigenvalues } \lambda_{i}. \text{ Consider } A^{\dagger} = (\sum_{i}{\lambda_i}\ket{i}\bra{i})^{\dagger} = \sum_{i}{\lambda_i^{*}\bra{i}^{\dagger}\ket{i}^{\dagger}}
    $$
    $$
    = \sum_{i}\lambda_{i}\ket{i}\bra{i} \text{ as } \lambda_i \text{ is real}. \implies A^{\dagger} = A \implies A \text{ is Hermitian}
    $$
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.18}
    
    \medskip

         \begin{equation}
          \text{For Unitary } U, \text{ following holds for its eigenpairs: } U\ket{v} = \lambda \ket{v} \implies \|U\ket{v}\|_2 = \| \lambda \ket{v}\|_2
      \end{equation}
      \begin{equation}
          \text{Say } \ket{\psi} = U\ket{v} \implies \bra{\psi} = \ket{\psi}^{\dagger} = \ket{v}^{\dagger}U^{\dagger} = \bra{\psi}U^{\dagger}
      \end{equation}
      $$
      \text{From } (2.16) \text{ we know, that } \|U\ket{v}\|_2 = \|\ket{\psi}\|_2 = \sqrt{\bra{\psi}\ket{\psi}} = \sqrt{\bra{v}U^{\dagger}U\ket{v}} = \sqrt{\bra{v}\ket{v}} = \|\ket{v}\|_2
      $$
      $$
      \text{Thus unitary transformations preserve the inner product and, therefore, the Euclidean      norm of vectors}.
      $$
      $$
      \text{We can rewrite } (1) \text{ as } \|\ket{v}\|_2 = \| \lambda \ket{v} \|_2 \implies | \lambda | = 1. \text{ It is a complex number on unit circle}.
      $$
      $$
      \lambda = \cos(\theta) + i \sin(\theta) = e^{i \theta} \text{ from Eulers Formula}.
    $$

    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.19: (Pauli matrices: Hermitian and unitary)}
    
    \medskip
    Matrix A is Hermitian if $A^{\dagger} = A$, matrix B is unitary if $B^{\dagger}B = BB^{\dagger} = I$ \\\\
    Now let's consider each of the Pauli matrices 
    \begin{enumerate}
        \item $\sigma_0 = I = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$\\\\
        $I^{\dagger} = (I^{T})^{*} = I $ as identity is symmetric, and complex conjugate of a real value is just itself, thus I is Hermitian. \\\\
        $I^{\dagger}I = II = I = II^{\dagger} \implies I$ is unitary

        \item $\sigma_1=\sigma_x=X = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}$\\\\
        $X^{\dagger} = (X^{T})^* = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}^{*} = X \implies X$ is Hermitian\\\\
        $X^{\dagger}X = XX = XX^{\dagger} = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} = I \implies X$ is unitary

        

        \item $\sigma_2=\sigma_y=Y = \begin{bmatrix} 0 & -i \\ i & 0 \end{bmatrix}$\\\\
        $Y^{\dagger} = (Y^{T})^* = \begin{bmatrix} 0 & i \\ -i & 0 \end{bmatrix}^{*} = \begin{bmatrix} 0 & -i \\ i & 0 \end{bmatrix} = Y \implies Y$ is Hermitian\\\\
        $Y^{\dagger}Y = YY = YY^{\dagger} = \begin{bmatrix} 0 & -i \\ i & 0 \end{bmatrix}\begin{bmatrix} 0 & -i \\ i & 0 \end{bmatrix}=\begin{bmatrix} -i^2 & 0 \\ 0 & -i^2 \end{bmatrix}=\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} = I \implies Y$ is unitary

        \item $\sigma_3=\sigma_z=Z = \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix}$\\\\
        $Z^{\dagger} = (Z^{T})^{*} = \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix}^{*} = Z \implies Z$ is Hermitian\\\\
        $Z^{\dagger}Z = ZZ = ZZ^{\dagger} = \begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix}\begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix}=\begin{bmatrix} 1 & 0 \\ 0 & (-1)^2 \end{bmatrix}=I \implies Z$ is unitary
    \end{enumerate}
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.20: (Basis changes)}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.21}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.22}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.23}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.24: (Hermiticity of positive operators)}
    
    \medskip

    $$\forall A, A = \frac{A}{2} + \frac{A}{2} = \frac{A}{2} + \frac{A}{2} + \frac{A^{\dagger}}{2} - \frac{A^{\dagger}}{2} = \frac{A + A^{\dagger}}{2} + \frac{A -A^{\dagger}}{2} = \frac{A + A^{\dagger}}{2} + i\frac{A -A^{\dagger}}{2i}.
    $$
    $$
    \text{Call } B = \frac{A + A^{\dagger}}{2} , C + \frac{A -A^{\dagger}}{2i} \implies A = B + iC.
    $$
    $$
    \text{Consider } B^{\dagger} = (\frac{A + A^{\dagger}}{2})^{\dagger} = (\frac{A^{\dagger} + (A^{\dagger})^{\dagger}}{2}) = (\frac{A^{\dagger} + A}{2}) = B \implies B \text{ is Hermitian}
    $$
    $$
    A \text{ is positive } \implies (\ket{v}, A\ket{v}) \in \mathbb{R}_{\geq 0} , \forall\ket{v}. \text{ Rewrite as } (\ket{v}, B\ket{v}) + i(\ket{v}, C\ket{v})
    $$
    $$
    \text{as inner product is linear in the second argument from (2.13)}
    $$
    $$
    (\ket{v}, C\ket{v}) = 0 \text{ as for any } \ket{v} \text{ quantity} (\ket{v}, A\ket{v}) \text{ is real}.
    $$
    $$
    \text{We have } (\ket{v}, A\ket{v}) = (\ket{v}, B\ket{v}) \implies (\ket{v}, (A-B)\ket{v}) = 0 \text{ from } (2.13)
    $$
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.25}
    
    \medskip
    Consider inner product $(\ket{v}, A^{\dagger}A\ket{v})$. Call $A\ket{v}$ to be $\ket{\psi}$, so we have $(\ket{v}, A^{\dagger}\ket{\psi}) = (A\ket{v}, \ket{\psi})$ from the definition of the Hermitian conjugate in (2.32), we get: $(\ket{\psi}, \ket{\psi}) \geq 0$ from the positivity property of inner product described on page 65.
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.26}
    $$\ket{\psi}^{\otimes2} = \ket{\psi} \otimes \ket{\psi} \text{, analogously } \ket{\psi}^{\otimes3} = \ket{\psi} \otimes \ket{\psi} \otimes \ket{\psi}$$
    Explicitly: 
    $$
    \ket{\psi}^{\otimes2} = (\frac{1}{\sqrt{2}}(\ket{0} + \ket{1})) \otimes (\frac{1}{\sqrt{2}}(\ket{0} + \ket{1})) = \frac{1}{2}((\ket{0} + \ket{1}) \otimes (\ket{0} + \ket{1})) \text{ from (2.42) }
    $$
    $$
    = \frac{1}{2}(\ket{0} \otimes \ket{0} + \ket{1} \otimes \ket{0} + \ket{0} \otimes \ket{1} + \ket{1} \otimes \ket{1}) \text{ from distributive properties (2.43. 2.44)}
    $$
    Using Kronecker product:
    $$
     \ket{0} = \begin{bmatrix}1 \\ 0\end{bmatrix}, \ket{1} = \begin{bmatrix}0 \\ 1\end{bmatrix}, so \ket{\psi}^{\otimes2} = \begin{bmatrix} \frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}}\end{bmatrix} \otimes \begin{bmatrix}\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}}\end{bmatrix} = \begin{bmatrix}\frac{1}{\sqrt{2}}\begin{bmatrix}\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}}\end{bmatrix} \\ \frac{1}{\sqrt{2}}\begin{bmatrix}\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}}\end{bmatrix}\end{bmatrix} = \frac{1}{2}\begin{bmatrix}1 \\ 1\\ 1\\ 1\end{bmatrix}
    $$
    Explicitly: 
    $$
    \ket{\psi}^{\otimes3} = (\frac{1}{\sqrt{2}}(\ket{0} + \ket{1})) \otimes (\frac{1}{\sqrt{2}}(\ket{0} + \ket{1})) \otimes (\frac{1}{\sqrt{2}}(\ket{0} + \ket{1})) = \frac{1}{2\sqrt{2}}((\ket{0} + \ket{1}) \otimes (\ket{0} + \ket{1})) \otimes (\ket{0} + \ket{1}))
    $$
    $$
    = \frac{1}{2\sqrt{2}}(\ket{0} \otimes \ket{0} \otimes \ket{0} + \ket{0} \otimes \ket{0} \otimes \ket{1} + \ket{0} \otimes \ket{1} \otimes \ket{0} + \ket{0} \otimes \ket{1} \otimes \ket{1} + \ket{1} \otimes \ket{0} \otimes \ket{0} + \ket{1} \otimes \ket{0} \otimes \ket{1} + 
    $$
    $$
    + \ket{1} \otimes \ket{1} \otimes \ket{0} + \ket{1} \otimes \ket{1} \otimes \ket{1})
    $$
    Using Kronecker product:
    $$
    \ket{\psi}^{\otimes3} = \ket{\psi}^{\otimes2} \otimes \ket{\psi} = (\frac{1}{2}\begin{bmatrix}1 \\ 1\\ 1\\ 1\end{bmatrix}) \otimes \begin{bmatrix} \frac{1}{\sqrt{2}}\\\frac{1}{\sqrt{2}}\end{bmatrix} = \frac{1}{2\sqrt{2}}\begin{bmatrix}1 \\ 1\\ 1\\ 1\end{bmatrix} \otimes \begin{bmatrix}1 \\1 \end{bmatrix} = \frac{1}{2\sqrt{2}}\begin{bmatrix}1 \\ 1\\ 1\\ 1\\ 1\\ 1\\ 1\\ 1\\ 1\end{bmatrix}
    $$
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.27}
    
    \medskip
    \begin{enumerate}
        \item 
        $$
        X \otimes Z = \begin{bmatrix}0 & 1\\ 1 & 0\end{bmatrix}\begin{bmatrix}1 & 0\\ 0 & -1\end{bmatrix} = 
        \begin{bmatrix}0\begin{bmatrix}1 & 0\\ 0 & -1\end{bmatrix} & 1\begin{bmatrix}1 & 0\\ 0 & -1\end{bmatrix}\\ 1\begin{bmatrix}1 & 0\\ 0 & -1\end{bmatrix} & 0\begin{bmatrix}1 & 0\\ 0 & -1\end{bmatrix}\end{bmatrix} = \begin{bmatrix} 0 & 0 & 1 & 0\\ 0 & 0& 0 & -1\\ 1 & 0 & 0 & 0\\ 0 & -1 & 0 & 0\end{bmatrix}
        $$
        \item 
        $$
        I \otimes X = \begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix} \otimes \begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} = \begin{bmatrix}1\begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} & 0\begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} \\ 0\begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} & 1\begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix}\end{bmatrix} = \begin{bmatrix} 0 & 1 & 0 & 0\\ 1 & 0 & 0 & 0\\ 0 & 0 & 0 & 1\\ 0 & 0 & 1 & 0\end{bmatrix}
        $$
        \item 
        $$
        X \otimes I = \begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} \otimes \begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix} = \begin{bmatrix}0\begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix} & 1\begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix} \\ 1\begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix} & 0\begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix}\end{bmatrix} =\begin{bmatrix} 0 & 0 & 1 & 0\\ 0 & 0 & 0 & 1\\ 1 & 0 & 0 & 0\\ 0 & 1 & 0 & 0\end{bmatrix}
        $$
        As parts 2 and 3 are different, we can conclude, that tensor product is not commutative.
    \end{enumerate}
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.28}
    
    \medskip
    Consider $(A \otimes B)^{*}$
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.29}
    
    \medskip
\textbf{Explicitly}
    $$
    \text{Consider unitary } A, B \text{ s.t } AA^{\dagger} = I, BB^{\dagger}=I. \text{ Assume } A \text{ is } m\times n \text{ matrix, and } B \text{ is } p \times q \text{ matrix}.
    $$
    $$
    \text{Then }A^{\dagger} \text{ is a } n\times m \text{ matrix, and } B^{\dagger} \text{ is a } q\times p \text{ matrix, as we are transposing, and}.
    $$
    $$
    \text{taking a conjugate of each element does not change the dimensions.}
    $$
    $$
    (A \otimes B)(A \otimes B)^{\dagger} = (A \otimes B)(A^{\dagger} \otimes B^{\dagger}) \text{ from (2.53)} 
    $$
    $$
    \text{From (2.50) } A \otimes B \text{ has } mp \text{ rows and } nq \text{ columns, and 
 } A^{\dagger} \otimes B^{\dagger} \text{ has } qn \text{ rows and } pm \text{ columns.}
    $$
    \begin{equation}
    A \otimes B = 
    \begin{bmatrix}
    a_{11}B & a_{12}B & \dots & a_{1n}B\\
    a_{21}B & a_{22}B & \dots & a_{2n}B\\
    \vdots  & \vdots && \vdots\\
    a_{m1}B & a_{m2}B &\dots & a_{mn}B
    \end{bmatrix}
    \text{where } a_{ij} \text{ are corresponding elements of } A 
    \end{equation}
    \begin{equation}
    A^{\dagger} \otimes B^{\dagger} = 
    \begin{bmatrix}
    a^{\dagger}_{11}B^{\dagger} & a^{\dagger}_{12}B^{\dagger} & \dots & a^{\dagger}_{1m}B^{\dagger}\\
    a_{21}B^{\dagger} & a_{22}B^{\dagger} & \dots & a_{2m}B^{\dagger}\\
    \vdots  & \vdots && \vdots\\
    a_{n1}B^{\dagger} & a_{n2}B^{\dagger} &\dots & a_{nm}B^{\dagger}
    \end{bmatrix}
    \text{where } a^{\dagger}_{ij} \text{ are corresponding elements of } A^{\dagger}
    \end{equation}
    As number of block rows in (1) is matching number of block columns in (2), and each block in (1) has the same number of columns as each block has rows in (2) then we can use Block Matrix Multiplication Formula.
    \begin{equation}
        C_{ij} = \sum_{k}a_{ik}Ba^{\dagger}_{kj}B^{\dagger} = \sum_{k}{a_{ik}a^{\dagger}_{kj}BB^{\dagger}} = \sum_{k}{a_{ik}a^{\dagger}_{kj}I_p} \text{ as } B \text{ is unitary}.
    \end{equation}
    $$
    \text{We know, that } AA^{\dagger} = I_m \implies (AA^{\dagger})_{ij} = (I_m)_{ij} \implies \sum_{k}{a_{ik}a^{\dagger}_{kj}} = \delta_{ij}
    $$
    $$
    \text{Thus, } C_{ij} = \begin{cases}I_p & i = j \\0 & i \neq j\end{cases} \implies (A \otimes B)(A^{\dagger} \otimes B^{\dagger}) = \begin{bmatrix}
    I_p & 0 & \dots & 0\\
    0 & I_p & \dots & 0\\
    \vdots  & \vdots && \vdots\\
    0 & 0 &\dots &I_p
    \end{bmatrix} 
    = I_{mp}
    $$
    $$
    \text{One could follow the same line of arguments as above to determine, that } (A^{\dagger} \otimes B^{\dagger})(A \otimes B) = I_{qn}
    $$
    $$
    \text{Thus tensor product of two unitary operators is unitary.}
    $$
\textbf{Mixed-product property} \\\\
Consider matrices $A, B, C, D$, where $A$ is $m \times n$, $B$ is $p \times q$, $C$ is $n \times r$, $D$ is $q \times s$. It is important, that number of columns in $A,B$ matches the number of rows in $C,D$ respectively. So when we compute $(A \otimes B)$ we have a matrix of size $ mp \times qn$, $(C \otimes D)$ we have a matrix of size $nq \otimes rs$, and when can multiply them, as the dimensions do match, we expect matrix of size $mp \times rs$ as a result.
$$
(A\otimes B)(C \otimes D) = 
\begin{bmatrix}
 \sum_k{a_{1k}Bc_{k1}D} & \sum_k{a_{1k}Bc_{k2}D} & \dots & \sum_k{a_{1k}Bc_{kr}D} \\
 \sum_k{a_{2k}Bc_{k1}D} & \sum_k{a_{2k}Bc_{k2}D} & \dots & \sum_k{a_{2k}Bc_{kr}D} \\
 \vdots  & \vdots && \vdots\\
 \sum_k{a_{mk}Bc_{k1}D} & \sum_k{a_{mk}Bc_{k2}D} & \dots & \sum_k{a_{mk}Bc_{kr}D} \\
\end{bmatrix}
=
$$
$$
=
\begin{bmatrix}
(AC)_{11}BD & (AC)_{12}BD & \dots & (AC)_{1r}BD \\
 (AC)_{21}BD & (AC)_{22}BD & \dots & (AC)_{2r}BD \\
 \vdots  & \vdots && \vdots\\
 (AC)_{m1}BD & (AC)_{m2}BD & \dots & (AC)_{mr}BD \\
\end{bmatrix} = (AC) \otimes (BD).
$$
\textbf{Using properties of tensor products} \\\\
$$
(A \otimes B)(A^{\dagger} \otimes B^{\dagger}) = (AA^{\dagger}) \otimes(BB^{\dagger}) = I_m \otimes I_p = I_{mp}
$$
$$
\text{with the number of rows and columns between the original matrix and the transpose matching trivially.}
$$

\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.30}
    
    \medskip
    $$
    \text{Consider Hermitian }A, B \text{ s.t } A^{\dagger}=A, B^{\dagger} = B. \text{ Now form } (A \otimes B)^{\dagger} = A^{\dagger} \otimes B^{\dagger} \text{ from (2.53)} = A \otimes B
    $$
    $$
    \text{Thus we have established, that the tensor product of two Hermitian matrices is Hermitian,}
    $$
    $$
    \text{as } (A \otimes B)^{\dagger} = A \otimes B
    $$
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.31}
    
    \medskip
    
    $$
    \text{From page 71 a positive operator A is defined as: } \forall \ket{v} (\ket{v}, A\ket{v}) \in \mathbb{R}_{\geq 0}
    $$  
    $$
    \text{Consider } A \otimes B, \text{ where } A,B \text{ are positive operators} \implies 
    (\ket{v}, (A \otimes B)\ket{v}) = 
    $$
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.32}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.33}
    
    \medskip

    \textbf{Computing} $H^{\otimes 2}$
    $$
    H^{\otimes 2} = H \otimes H = \frac{1}{\sqrt{2}}\begin{bmatrix}1 & 1 \\ 1 & -1\end{bmatrix} \otimes \frac{1}{\sqrt{2}}\begin{bmatrix}1 & 1 \\ 1 & -1\end{bmatrix} = \frac{1}{2}
    \begin{bmatrix}
    1 \begin{bmatrix}1 & 1 \\ 1 & -1\end{bmatrix} &
    1 \begin{bmatrix}1 & 1 \\ 1 & -1\end{bmatrix} \\
    1 \begin{bmatrix}1 & 1 \\ 1 & -1\end{bmatrix} & 
    -1 \begin{bmatrix}1 & 1 \\ 1 & -1\end{bmatrix} \\
    \end{bmatrix} =
    \begin{bmatrix}
        1 & 1 & 1 & 1 \\
        1 & -1 & 1 & -1 \\
        1 & 1 & -1 & -1 \\
        1 & -1 & -1 & 1
    \end{bmatrix}
    $$
    $$
    \text{Now using the formula } H^{\otimes 2} = \frac{1}{\sqrt{2^2}} \sum_{x,y \in \{0, 1\}^2}{(-1)^{xy}\ket{x}\bra{y}} = \sum_{x,y \in \{00, 01, 10, 11 \}}{(-1)^{xy}\ket{x}\bra{y}}
    $$
    \textbf{Base case n = 1}
    $$
    \text{Substituting } \ket{1} \text{ with } \begin{bmatrix}1 \\ 0\end{bmatrix} \text{ and } \ket{0} \text{ with } \begin{bmatrix}0 \\ 1\end{bmatrix} $$
    $$\text{ (2.54) becomes } H = \frac{1}{\sqrt{2}}[(\begin{bmatrix}1 \\ 0\end{bmatrix} + \begin{bmatrix}0 \\ 1\end{bmatrix})\begin{bmatrix}1 & 0\end{bmatrix} + (\begin{bmatrix}1 \\ 0\end{bmatrix} - \begin{bmatrix}0 \\ 1\end{bmatrix})\begin{bmatrix}0 & 1\end{bmatrix}]
    $$
    $$
    = \frac{1}{\sqrt2}(\begin{bmatrix}1 \\ 1\end{bmatrix}\begin{bmatrix}1 & 0\end{bmatrix} + \begin{bmatrix}1 \\ -1\end{bmatrix}\begin{bmatrix}0 & 1\end{bmatrix}) = \frac{1}{\sqrt{2}}(\begin{bmatrix}1 & 0 \\ 1 & 0\end{bmatrix}+\begin{bmatrix} 0 & 1 \\ 0 & -1\end{bmatrix}) = \frac{1}{\sqrt{2}}\begin{bmatrix}1 & 1 \\ 1 & -1\end{bmatrix}
    $$
    $$
    \text{Which is indeed the classical matrix representation of the Hadamard operator}
    $$
    \textbf{Indiction hypothesis n = k}
    $$
    \text{ Assume for } n = k \text{ the following holds } H^{\otimes k} = \frac{1}{\sqrt{2^k}}\sum_{x,y\in \{0,1\}^k}{(-1)^{xy}\ket{x}\bra{y}}
    $$
    $$
    \text{The subscript in the sum directly above just means, that x and y are binary strings of length k}
    $$
    \textbf{Induction step n = k + 1}
    $$
    H^{\otimes (k+1)} = (\frac{1}{\sqrt{2}}[(\ket{0}+\ket{1})\bra{0} + (\ket{0}-\ket{1})\bra{1}]) \otimes \frac{1}{\sqrt{2^k}}\sum_{x,y\in \{0,1\}^k}{(-1)^{xy}\ket{x}\bra{y}}
    $$
    $$
    = (\frac{1}{\sqrt{2}}(\ket{0}\bra{0} + \ket{1}\bra{0} + \ket{0}\bra{1} - \ket{1}\bra{1}) \otimes H^{\otimes k}
    $$
    $$
    = \frac{1}{\sqrt{2^1}}\sum_{x,y \in \{0, 1\}}{(-1)^{xy}\ket{x}\bra{y}} \otimes \frac{1}{\sqrt{2^k}}\sum_{x,y\in \{0,1\}^k}{(-1)^{xy}\ket{x}\bra{y}} \overset{*}{=}
    $$
    $$
    \text{We compute } xy \text{ to determine the sign by performing the binary inner product} 
    $$
\begin{table}[H] 
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        xy & x & y \\ 
        \hline
        0 & 0 & 0 \\
        0 & 0 & 1 \\
        0 & 1 & 0 \\
        1 & 1 & 1 \\
        \hline
    \end{tabular}
    \caption{$xy \in \{0,1\}$}
    \label{tab:binary_inner_product}
\end{table}
\begin{table}[H] 
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        $xy = x_1y_1 + x_2y_2 \mod 2$ & $x=x_1x_2$ & $y=y_1y_2$ \\ 
        \hline
        0 & 00 & 00 \\ 0 & 00 & 01 \\ 0 & 00 & 10 \\ 0 & 00 & 11 \\ 
        0 & 01 & 00 \\ 1 & 01 & 01 \\ 0 & 01 & 10 \\ 1 & 01 & 11 \\ 
        0 & 10 & 00 \\ 0 & 10 & 01 \\ 1 & 10 & 10 \\ 1 & 10 & 11 \\ 
        0 & 11 & 00 \\ 1 & 11 & 01 \\ 1 & 11 & 10 \\ 0 & 11 & 11 \\ 
        \hline
    \end{tabular}
    \caption{Binary inner product mod 2 for $x, y \in \{0,1\}^2$}
    \label{tab:binary_inner_product}
\end{table}
    \begin{equation}
        \text{We can extend (2.43, 2.44) to } \sum_{i}{\ket{a_i}} \otimes \sum_{i}{\ket{b_i}} = \sum_{i}\sum_{j}{(\ket{a_i} \otimes \ket{b_i})}
        \tag{1}
    \end{equation}
    $$
    = \frac{1}{\sqrt{2^{k+1}}}\sum_{x',y'\in\{0,1\}}\sum_{x'',y''\in\{0,1\}^k}{((-1)^{x'y'}\ket{x'}\bra{y'}) \otimes ((-1)^{x''y''}\ket{x''}\bra{y''})}
     \text{ from (1)}
    $$
    $$
    = \frac{1}{\sqrt{2^{k+1}}}\sum_{x',y'\in\{0,1\}}\sum_{x'',y''\in\{0,1\}^k}{(-1)^{x'y'}(-1)^{x''y''}[(\ket{x'}\bra{y'}) \otimes (\ket{x''}\bra{y''})]}
     \text{ from (2.42)} \overset{**}{=}
    $$
    $$
    \text{We want to perform the change of variables where } x \text{ is } (x', x''), \text{ where } x' \text{ is 1 bit and } x'' \text{ is k bit long}   
    $$
    $$
    \{0,1\} \times \{0,1\}^k = \{(x, y) \mid x \in \{0,1\}, y \in \{0,1\}^k\} = \{(0, y) \mid y \in \{0,1\}^k\} \cup \{(1, y) \mid y \in \{0,1\}^k\} = \{0,1\}^{k+1}
    $$
    $$
    \text{So, Considering } (-1)^{x'y'}(-1)^{x''y''} \text { we expand the definition of the binary inner product and have: } 
    $$
    $$
    (-1)^{x'y'}(-1)^{\sum_{i = 1}^{k}{x_i}} = 
    $$


\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.34}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.35: (Exponential of the Pauli matrices)}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.36}
    
    \medskip
    
    \begin{itemize}
        \item $X = \begin{bmatrix} 0 & 1 \\ 1 & 0\end{bmatrix} 0 + 0 = 0 \implies \operatorname{tr}(X) = 0  $.
        \item $Y = \begin{bmatrix} 0 & -i \\ i & 0\end{bmatrix} 0 + 0 = 0 \implies \operatorname{tr}(Y) = 0  $.
        \item $Z = \begin{bmatrix} 1 & 0 \\0 & -1\end{bmatrix} 1 - 1 = 0 \implies \operatorname{tr}(Z) = 0 $.
    \end{itemize}
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.37: (Cyclic property of the trace)}
    
    \medskip

    $$
    \operatorname{tr}(AB) = \sum_{i=1}^{n}{AB}_{ii} = \sum_{i=1}^{n}\sum_{j=1}^{n}A_{ij}B_{ji} \text{ from the definition of matrix multiplication}
    $$
    $$
    = \sum_{i=1}^{n}\sum_{j=1}^{n}{B_{ji}A_{ij}} \text{, as } B_{ji} \text{ and } A_{ij} \text{ are elements of the matrix and thus commutative scalars}
    $$
    $$
    = \sum_{j=1}^{n}\sum_{i=1}^{n}{B_{ji}A_{ij}} \textbf{ !!TODO!! ASK A QUESTION}
    $$
    $$
    = \sum_{j=1}^{n}(BA)_{jj} = \operatorname{tr}(BA)
    $$
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.38: (Linearity of the trace)}
    
    \medskip

    $$
    \operatorname{tr}(A + B) = \sum_{i=1}^{n}{(A + B)_{ii}} = \sum_{i=1}^{n}A_{ii} + \sum_{i=1}^{n}B_{ii} = \operatorname{tr}(A) + \operatorname{tr}(B) \text{, as matrix addition is entry-wise}.
    $$
    $$
    \text{For } z \in \mathbb{C} \text{ consider } \operatorname{tr}(zA) = 
    \sum_{i=1}^{n}{(zA)_{ii}} = \sum_{i=1}^{n}{zA_{ii}} = z\sum_{i=1}^{n}{A_{ii}} = z\operatorname{tr}(A)
    $$
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.39: (The Hilbertâ€“Schmidt inner product on operators)}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.40: (Commutation relations for the Pauli matrices)}
    
    \medskip
    \begin{enumerate}
        \item $[X, Y] = XY - YX = \begin{bmatrix}0 & 1 \\ 1 & 0 \end{bmatrix}\begin{bmatrix}0 & -i \\ i & 0\end{bmatrix}-\begin{bmatrix}0 & -i \\ i & 0\end{bmatrix}\begin{bmatrix}0 & 1 \\ 1 & 0 \end{bmatrix} = \begin{bmatrix}i & 0 \\ 0 & -i \end{bmatrix}-\begin{bmatrix}-i & 0 \\ 0 & i \end{bmatrix}= \begin{bmatrix}2i & 0 \\ 0 & -2i \end{bmatrix} = 2i\begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix} = 2iZ$
        \item $[Y, Z] = YZ - ZY = \begin{bmatrix}0 & -i \\ i & 0 \end{bmatrix}\begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix} - \begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix}\begin{bmatrix}0 & -i \\ i & 0 \end{bmatrix} = \begin{bmatrix}0 & i \\ i & 0\end{bmatrix} - \begin{bmatrix}0 & -i \\ -i & 0\end{bmatrix} = \begin{bmatrix}0 & 2i \\ 2i & 0\end{bmatrix} = 2i\begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} = 2iX$
        \item $[Z, X] = ZX - XZ = \begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix}\begin{bmatrix}0 & 1 \\ 1 & 0 \end{bmatrix} - \begin{bmatrix}0 & 1 \\ 1 & 0 \end{bmatrix}\begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix} = \begin{bmatrix}0 & 1 \\ -1 & 0\end{bmatrix} - \begin{bmatrix}0 & -1 \\ 1 & 0\end{bmatrix} = \begin{bmatrix}0 & 2 \\ -2 & 0\end{bmatrix} = 2i\begin{bmatrix}0 & -i \\ i & 0\end{bmatrix} = 2iY$
    \end{enumerate}
    Note, that $\epsilon_{jkl}$ in (2.74) is Levi-Civita symbol.
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.41: (Anti-commutation relations for the Pauli matrices)}
    
    \medskip
    \begin{enumerate}
        \item $\{\sigma_1, \sigma_2\} = XY + YX = \begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} \begin{bmatrix}0 & -i \\ i & 0\end{bmatrix} + \begin{bmatrix}0 & -i \\ i & 0\end{bmatrix} \begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} = \begin{bmatrix}i & 0 \\ 0 & -i\end{bmatrix} + \begin{bmatrix}-i & 0 \\ 0 & i\end{bmatrix} = \begin{bmatrix}0 & 0 \\ 0 & 0\end{bmatrix} = 0$
        \item $\{\sigma_2, \sigma_3\} = YZ + ZY = \begin{bmatrix}0 & -i \\ i & 0\end{bmatrix} \begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix} + \begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix} \begin{bmatrix}0 & -i \\ i & 0\end{bmatrix} = \begin{bmatrix}0 & -i \\ -i & 0\end{bmatrix} + \begin{bmatrix}0 & i \\ i & 0\end{bmatrix} = \begin{bmatrix}0 & 0 \\ 0 & 0\end{bmatrix} = 0$
        \item $\{\sigma_3, \sigma_1\} = ZX + XZ = \begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix} \begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} + \begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} \begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix} = \begin{bmatrix}0 & 1 \\ -1 & 0\end{bmatrix} + \begin{bmatrix}0 & -1 \\ 1 & 0\end{bmatrix} = \begin{bmatrix}0 & 0 \\ 0 & 0\end{bmatrix} = 0$
        \item $\sigma_1^2  = XX= \begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} \begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix} = \begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix} = I$
        \item $\sigma_2^2  = YY= \begin{bmatrix}0 & -i \\ i & 0\end{bmatrix} \begin{bmatrix}0 & -i \\ i & 0\end{bmatrix} = \begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix} = I$
        \item $\sigma_3^2  = ZZ= \begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix} \begin{bmatrix}1 & 0 \\ 0 & -1\end{bmatrix} = \begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix} = I$


    \end{enumerate}
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.42}
    
    \medskip
    $$
    \text{Consider }  \frac{[A,B] +\{A,B\}}{2} = \frac{AB - BA + AB + BA}{2} \text{ from (2.66), (2.67)}
    $$
    $$
    = \frac{2AB}{2} = AB
    $$
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.43}
    
    \medskip
    \begin{equation*}
        \text{Note, that Kronicker delta is defined as } \delta_{jk} =
        \begin{cases}
            0, & \text{if } j \neq k, \\
            1, & \text{if } j = k.
        \end{cases}
    \end{equation*}
    \begin{equation*}
        \text{1. Consider the case } j\neq k \text{, then from (2.74, 2.75) } [\sigma_j, \sigma_k] + \{\sigma_j, \sigma_k \} = 2i\sum_{l=1}^{3}\epsilon_{jkl}\sigma_l + 0
    \end{equation*}
    \begin{equation*}
        \text{Expanding the commutator and anti-commutator using their definitions we get: }
    \end{equation*}
    \begin{equation*}
        \sigma_j\sigma_k - \sigma_k\sigma_j + \sigma_j\sigma_k + \sigma_k\sigma_j = 2i\sum_{l=1}^{3}\epsilon_{jkl}\sigma_l \implies 2\sigma_j\sigma_k = 2i\sum_{l=1}^{3}\epsilon_{jkl}\sigma_l \implies
        \sigma_j\sigma_k = i\sum_{l=1}^{3}\epsilon_{jkl}\sigma_l
    \end{equation*}
    \begin{equation*}
        \delta_{jk} = 0 \text{ as } j \neq k \implies \delta_{jk}I = 0 \implies \sigma_j\sigma_k = \delta_{jk}I + i\sum_{l=1}^{3}\epsilon_{jkl}\sigma_l
    \end{equation*}
    \begin{equation*}
        \text{2. Now consider the case } j = k \implies \delta_{jk} = 1 \text{ and from (2.76) } \sigma_{jk}\sigma_{jk} = I \implies \sigma_{jk} = \delta_{jk}I.
    \end{equation*}
    \begin{equation*}
        \text{Consider }\sigma_j\sigma_k = 2i\sum_{l=1}^{3}\epsilon_{jkl}\sigma_l = 2i(\epsilon_{jk1}\sigma_1+\epsilon_{jk2}\sigma_2+\epsilon_{jk2}\sigma_3z) = 2i(0) = 0
    \end{equation*}
    \begin{equation*}
        \text{ because in all the cases } \epsilon \text{ would have a repeating index, as } j = k.
    \end{equation*}
    \begin{equation*}
        \text{ We have established, that } \sigma_{jk} = \delta_{jk}I + \sum_{l=1}^3{\epsilon_{jkl}\sigma_l} \text{ } \forall j,k
    \end{equation*}

    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.44}
    $$
    [A,B] = 0 \implies AB - BA = 0, \{A, B\} = 0 \implies AB + BA = 0 \text{ from definitions (2.66, 2.67)}
    $$
    $$
    \text{Then their sum } [A,B] + \{A,B\} = 2AB = 0 \text{ We now multiply both sides on the left by } A^{-1} \text{}
    $$
    $$
    A^{-1}2AB = A^{-1}0 \implies 2B = 0 \implies B = 0.
    $$
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.45}
    
    \medskip
    
    Consider Hermitian conjugate of a commutator between two operators A and B 
    $$
    [A,B]^{\dagger} = (AB - BA)^{\dagger} \text{ from (2.66)}
    $$
    $$
    = ((AB - BA)^{T})^{*} \text{ from definition of Hermitian conjugate}
    $$
    $$
    = ((AB)^{T} - (BA)^{T}) ^ {*} = (B^TA^T - A^TB^T)^* = (B^T)^*(A^T)^* - (A^T)^*(B^T)^*
    $$
    $$
    = B^{\dagger}A^{\dagger} - A^{\dagger}B^{\dagger} = [B^{\dagger},A^{\dagger}]
    $$
\end{framed}

\bigskip
\begin{framed}
\noindent \textbf{Exercise 2.46}

\medskip

Consider $[A, B] = AB - BA = -(-AB + BA) = - (BA - AB) = -[B, A]$
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.47}
    
    \medskip

    $$
    A, B \text{ are Hermitian, then each is equal to their conjugate transpose } A = A^{\dagger}, B = B^{\dagger}
    $$
    $$
    \text{Consider } (i[A, B])^{\dagger} = i^{*}[A,B]^{\dagger} \text{ as } (cA)^{\dagger} = c^{*}A^{\dagger} \text{ where } c \text{ is a complex scalar}.
    $$
    $$
    = (-i)[A, B]^{\dagger} = (-i)[B^{\dagger},A^{\dagger}] \text{ from Exercise 2.45}
    $$
    $$
    = (-i)[B, A] = -(i)(-[A,B]) \text{ from exercise 2.46} = i[A,B] \implies i[A,B] \text{ is Hermitian}
    $$
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.48}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.49}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.50}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.51}
    
    \medskip
    $$
    \text{Consider } HH^{\dagger} = \frac{1}{\sqrt{2}}\begin{bmatrix}1 & 1\\ 1 & -1\end{bmatrix}\frac{1}{\sqrt{2}}\begin{bmatrix}1 & 1\\ 1 & -1\end{bmatrix}=\frac{1}{2}\begin{bmatrix}2 & 0 \\ 0 & 2\end{bmatrix}=I
    $$
    $$
    \text{Consider }H^{\dagger}H = \frac{1}{\sqrt{2}}\begin{bmatrix}1 & 1\\ 1 & -1\end{bmatrix}\frac{1}{\sqrt{2}}\begin{bmatrix}1 & 1\\ 1 & -1\end{bmatrix}=\frac{1}{2}\begin{bmatrix}2 & 0 \\ 0 & 2\end{bmatrix}=I
    $$
    Thus H is indeed unitary.
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.52}
    
    \medskip

    $$
    H^2 = \frac{1}{2}\begin{bmatrix}1 & 1\\ 1 & -1\end{bmatrix}\begin{bmatrix}1 & 1\\ 1 & -1\end{bmatrix} = \frac{1}{2}\begin{bmatrix} 1\times1 + 1\times1 & 1\times1 - 1\times1 \\ 1 \times 1 - 1 \times 1 & 1 \times 1 + (-1)\times(-1)\end{bmatrix} = \frac{1}{2}\begin{bmatrix}2 & 0 \\ 0 & 2\end{bmatrix} = I
    $$
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.53}
    
    \medskip
    $$
    \text{Consider characteristic question } (\frac{1}{\sqrt{2}} - \lambda)(-\frac{1}{\sqrt{2}} - \lambda) - \frac{1}{2} = 0 \implies \lambda^2=1 \implies\lambda = \pm 1.
    $$
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.54}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.55}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.56}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.57: (Cascaded measurements are single measurements)}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.58}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.59}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.60}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.61}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.62}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.63}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.64}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.65}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.66}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.67}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.68}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.69}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.70}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.71: (Criterion to decide if a state is mixed or pure)}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.72: (Bloch sphere for mixed states)}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.73}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.74}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.75}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.76}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.77}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.78}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.79}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.80}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.81: (Freedom in purifications)}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 2.82}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{End of Chapter Exercise 2.1: (Functions of the Pauli matrices)}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{End of Chapter Exercise 2.2: (Properties of the Schmidt number)}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{End of Chapter Exercise 2.3: (Tsirelsonâ€™s inequality)}
    
    \medskip
    
    
\end{framed}

\subsection*{Chapter 3: Introduction to computer science}

\begin{center}
\begin{tabular}{*{7}{c}}
\toprule
\notStarted{1} & \solved{2} & \notStarted{3} & \inProgress{4} & \notStarted{5} & \notStarted{6} & \notStarted{7} \\
\notStarted{8} & \notStarted{9} & \notStarted{10} & \solved{11} & \solved{12} & \notStarted{13} & \notStarted{14} \\
\notStarted{15} & \notStarted{16} & \notStarted{17} & \notStarted{18} & \notStarted{19} & \notStarted{20} & \notStarted{21} \\
\notStarted{22} & \notStarted{23} & \notStarted{24} & \notStarted{25} & \notStarted{26} & \notStarted{27} & \notStarted{28} \\
\notStarted{29} & \notStarted{30} & \notStarted{31} & \notStarted{32} & \notStarted{EOC1} & \notStarted{EOC2} & \notStarted{EOC3} \\
\notStarted{EOC4} & \notStarted{EOC5} & \notStarted{EOC6} & \notStarted{EOC7} & \notStarted{EOC8} & \notStarted{EOC9} & \notStarted{EOC10} \\
\bottomrule
\end{tabular}
\end{center}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.1: Non-computable processes in Nature}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.2: Turing numbers}
    
    \medskip
    A Turing Machine is just a seven-tuple $(Q, \Sigma, \Gamma, \delta, q_0, a_{accept}, a_{reject})$, where:
    \begin{itemize}
        \item $Q$ is a set of States
        \item $\Sigma$ is the input alphabet 
        \item $\Gamma$ is the tape alphabet, $\square \in \Gamma, \Sigma \subseteq \Gamma$
        \item $\delta: Q \times \Gamma \rightarrow Q \times \Gamma \times \{L,R\}$ is the transition function
        \item  $q_0 \in Q$ is the accept state
        \item $a_{accept} \in Q$ is the accept state
        \item $q_{recect} \in Q$ is the reject state $q_{reject} \neq q_{accept}$
    \end{itemize}
A more detailed explanation of the definition you can find in "Introduction to Theory of Computation" by Michael Sipser, so:
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.3: Turing machine to reverse a bit string}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.4: Turing machine to add modulo 2}

    \medskip

    Given two input strings separated by a blank character, we traverse to the last character of the second string (we know this if it is a second blank we encounter, the first one being the separation between the input strings of bits). Based on the value of the last bit, we either transition to a last 1 (q5) state or a last 0 (q4) state. We now have to see what was the last bit in the first input string, so we traverse left, deleting every bit we encounter, not to leave a huge mess after us. Once we encounter the last bit within the first input string, we decide accordingly on what to write on the tape (if we already have 1 from the second input string and encounter 0 now, we write 1, and if we encounter 1, we write 0). We can do addition modulo 2 based on these last two bits.
    
    \begin{center}
        \includegraphics[width=1.1\textwidth]{images/3.4TM.jpg}
        \captionof{figure}{Single-Tape TM}
    \end{center}

    Let's carefully trace what is happening if we want to add 7 and 9 modulo 2. Our tape initially looks like $\dots \square \square q_0111 \square 1001 \square \square \dots$ with the head on the very first digit if the first input string, the machine is in the position q0.
    \begin{align*}
        &\square\ \square\ q_0\ 1\ 1\ 1\ \square\ 1\ 0\ 0\ 1\ \square\ \square\ \\
        &\square\ \square\ 1\ q_0\ 1\ 1\ \square\ 1\ 0\ 0\ 1\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ q_0\ 1\ \square\ 1\ 0\ 0\ 1\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ 1\ q_0\ \square\ 1\ 0\ 0\ 1\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ 1\ \square\ q_1\ 1\ 0\ 0\ 1\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ 1\ \square\ 1\ q_1\ 0\ 0\ 1\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ 1\ \square\ 1\ 0\ q_1\ 0\ 1\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ 1\ \square\ 1\ 0\ 0\ q_1\ 1\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ 1\ \square\ 1\ 0\ 0\ 1\ q_1\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ 1\ \square\ 1\ 0\ 0\ q_6\ 1\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ 1\ \square\ 1\ 0\ q_5\ 0\ \square\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ 1\ \square\ 1\ q_5\ 0\ \square\ \square\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ 1\ \square\ q_5\ 1\ \square\ \square\ \square\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ 1\ q_5\ \square\ \square\ \square\ \square\ \square\ \square\ \square\ \\
        &\square\ \square\ 1\ 1\ q_8\ 1\ \square\ \square\ \square\ \square\ \square\ \square\ \square\ \\
        &\square\ \square\ 1\ q_9\ 1\ 0\ \square\ \square\ \square\ \square\ \square\ \square\ \square\ \\
        &\square\ \square\ q_9\ 1\  \square\ 0\ \square\ \square\ \square\ \square\ \square\ \square\ \square\ \\
        &\square\ q_9\ \square\  \square\ \square\ 0\ \square\ \square\ \square\ \square\ \square\ \square\ \square\ \\
        &q_{10}\square\ \ \square\  \square\ \square\ 0\ \square\ \square\ \square\ \square\ \square\ \square\ \square\ \\
\end{align*}
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.5: Halting problem with no inputs}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.6: Probabilistic halting problem}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.7: Halting oracle}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.8: Universality of NAND}
    
    \medskip
    Note: here I use Sheffer stroke $\uparrow$ notation for NAND
    \begin{itemize}
        \item \textbf{AND}
        $A \land B = (A \uparrow B) \uparrow (A \uparrow B)$
        $$
        \begin{array}{c|c|c|c|c|c}
        A & B & A \uparrow B & A \land B & (A \uparrow B) \uparrow (A \uparrow B)\\
        \hline
        0 & 0 & 1 & 0 & 0\\
        0 & 1 & 1 & 0 & 0\\
        1 & 0 & 1 & 0 & 0\\
        1 & 1 & 0 & 1 & 1\\
        \end{array}
        $$
        % \begin{figure}[h]
        %     \centering
        %     \begin{circuitikz}[scale=1.0, transform shape]
        %         \node[american nand port, number inputs=2] (NAND1) at (0,0) {};
        %         \draw (NAND1.in 1) node[left] {A};
        %         \draw (NAND1.in 2) node[left] {B};
        %         \draw (NAND1.out) -- ++(1,0) coordinate (midOut);
        %         \node[american nand port, number inputs=2] (NAND2) at (3,0) {};
        %         \draw (midOut) |- (NAND2.in 1);
        %         \draw (midOut) |- (NAND2.in 2);
        %         \draw (NAND2.out) -- ++(1,0) node[right] {A AND B};
        %     \end{circuitikz}
        %     \caption{An AND gate using two NAND gates.}
        % \end{figure}
        \item \textbf{NOT} $\lnot A = A \uparrow A$
        $$
        \begin{array}{c|c|c|c|c|c}
        A & \lnot A & A \uparrow A \\
        \hline
        0 & 1 & 1\\
        1 & 0 & 0\\
        \end{array}
        $$
        \item \textbf{Or} $A \lor B = \lnot(\lnot A \land \lnot B) = \lnot A \uparrow \lnot B = (A \uparrow A) \uparrow (B \uparrow B)$ from the De Morgan's Law.
        $$
        \begin{array}{c|c|c|c|c|c|c|c|c|c}
        A & B & \lnot A & \lnot B & \lnot A \land \lnot B & \lnot(\lnot A \land \lnot B) & A \uparrow A & B \uparrow B &(A \uparrow A) \uparrow (B \uparrow B) & A \lor B \\
        \hline
        0 & 0 & 1 & 1 & 1 & 0 & 1 & 1 & 0 & 0\\
        0 & 1 & 1 & 0 & 0 & 1 & 1 & 0 & 1 & 1\\
        1 & 0 & 0 & 1 & 0 & 1 & 0 & 1 & 1 & 1\\
        1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 1\\
        \end{array}
        $$

        \item $A \oplus B = (A \land \lnot B) \lor (\lnot A \land B)$.
    \end{itemize}
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.9: }
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.10: }
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.11}
    
    \medskip
    We need to prove, that $\exists $ constants $c,n_0$ s.t $\forall n \geq n_0, \log n \leq cn^{k}, k > 0$. 

    $$
    \text{Consider } \lim_{n \rightarrow \infty}{\frac{\log n}{n^{k}}} \xrightarrow[]{L'Hopital's rule} \lim_{n \rightarrow \infty}{\frac{\frac{1}{n}}{kn^{k-1}}} = \lim_{n \rightarrow \infty}{\frac{1}{kn^{k}}} = 0 \implies \frac{\log{n}}{n^k} \leq 1 \text{ for some large } n.
    $$
    $$
    \text{For } c = 1 \text{ and some large } n, \log{n} \leq n^{k}, \text{ as we are considering the non-negative functions}. 
    $$
    $$
    \text{Thus } \log{n} \text{ is } O(n^{k}).
    $$
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.12: } $n^{\log{n}}$ \textbf{ is super-polynomial}
    
    \medskip
    We need to prove, that $\forall k, \exists c, n_0$, s.t $\forall n > n_0, n^{k} \leq cn^{\log{n}}$ Consider:
    $$
    \lim_{n \rightarrow \infty}{\frac{n^k}{n^{\log{n}}}} = \lim_{n \rightarrow \infty}{\frac{(e^{\ln{n}})^{k}}{(e^{\ln{n}})^{\log{n}}}} = \lim_{n \rightarrow \infty}{\frac{e^{k\ln{n}}}{e^{\log{n}\ln{n}}}} = \lim_{n \rightarrow \infty}{e^{k\ln{n} - \log{n}\ln{n}} = e^{-\infty} = 0}
    $$
    $$
    \text{as } k \text{ is a fixed constant.} \text{ In conclusion } c = 1 \text{ and some large } n, n^{k} \leq n^{\log{n}} \implies n^{k} \text{ is } O(n^{\log{n}})
    $$
    $$
    \text{Suppose for contradiction  } n^{\log{n}} \text{ is } O(n^k) \implies \exists c, n_0, \text{ s.t } n^{\log{n}} \leq cn^{k}, \forall n > n_0 \implies \ln{n^{\log{n}}} \leq \ln{cn^{k}}
    $$
    $$
    \implies \log{n} \ln{n} \leq \ln{c} + k \ln{n} \implies \ln{n}(\log{n} - k) \leq \ln{c}.
    $$
    $$
    \text{ But, as } n \rightarrow \infty 
    \text{ the left side tends to infinity, and it cannot be less, than some constant.}
    $$
    $$\text{Thus we have a contradiction, and out initial statement is false, thus } n^{\log{n}} \text{ is never } O(n^k).
    $$

    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.13: } $n^{\log{n}}$ \textbf{ is sub-exponential}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.14: }
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.15: Lower bound for compare-and-swap based sorts}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.16}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.17}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.18}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.19}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.20}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.21}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.22}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.23}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.24}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.25}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.26}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.27}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.28}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.29}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.30}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.31}
    
    \medskip
    
    
\end{framed}

\bigskip

\begin{framed}
    \noindent \textbf{Exercise 3.32}
    
    \medskip
    
    
\end{framed}

\subsection*{Chapter 4: Quantum circuits}

\begin{center}
\begin{tabular}{*{9}{c}}
\toprule
\notStarted{1} & \notStarted{2} & \notStarted{3} & \notStarted{4} & \notStarted{5} & \notStarted{6} & \notStarted{7} & \notStarted{8} & \notStarted{9} \\
\notStarted{10} & \notStarted{11} & \notStarted{12} & \notStarted{13} & \notStarted{14} & \notStarted{15} & \notStarted{16} & \notStarted{17} & \notStarted{18} \\
\notStarted{19} & \notStarted{20} & \notStarted{21} & \notStarted{22} & \notStarted{23} & \notStarted{24} & \notStarted{25} & \notStarted{26} & \notStarted{27} \\
\notStarted{28} & \notStarted{29} & \notStarted{30} & \notStarted{31} & \notStarted{32} & \notStarted{33} & \notStarted{34} & \notStarted{35} & \notStarted{36} \\
\notStarted{37} & \notStarted{38} & \notStarted{39} & \notStarted{40} & \notStarted{41} & \notStarted{42} & \notStarted{43} & \notStarted{44} & \notStarted{45} \\
\notStarted{46} & \notStarted{47} & \notStarted{48} & \notStarted{49} & \notStarted{50} & \notStarted{51} & \notStarted{EOC1} & \notStarted{EOC2} & \notStarted{EOC3} \\
\notStarted{EOC4} & \notStarted{EOC5} & \notStarted{EOC6} &  &  &  &  &  &  \\
\bottomrule
\end{tabular}
\end{center}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.1}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.2}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.3}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.4}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.5}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.6}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.7}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.8}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.9}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.10}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.11}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.12}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.13}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.14}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.15}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.16}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.17}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.18}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.19}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.20}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.21}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.22}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.23}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.24}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.25}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.26}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.27}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.28}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.29}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.30}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.31}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.32}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.33}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.34}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.35}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.36}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.27}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.38}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.39}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.40}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.41}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.42}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.43}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.44}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.45}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.46}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.47}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.48}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.49}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.50}
    
    \medskip
    
    
\end{framed}


\bigskip

\begin{framed}
    \noindent \textbf{Exercise 4.51}
    
    \medskip
    
    
\end{framed}

\subsection*{Chapter 5: The quantum Fourier transform and its applications}
\subsection*{Chapter 6: Quantum search algorithms}
\subsection*{Chapter 7: Quantum computers: physical realization}
\subsection*{Chapter 8: Quantum noise and quantum operations}
\subsection*{Chapter 9: Distance measures for quantum information }
\subsection*{Chapter 10: Quantum error-correction}
\subsection*{Chapter 11: Entropy and information}
\subsection*{Chapter 12: Quantum information theory }

\end{document}